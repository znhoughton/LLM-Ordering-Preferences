---
title: "Analysis"
author: "Zach"
date: "2024-02-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(brms)
library(mgcv)
corpus = read_csv('../Data/corpus.csv')
```

# Analysis

Within this script will be the analyses for the study about ordering preferences in LLMs.

We care about how the effects of generative preferences and observed (relative) frequency change as a function of the overall frequency of the binomial.

This script will be divided into two main sections:

1.  The analyses for just the binomial (*cat and dog*)
2.  The analyses for the binomial within a sentence context*.*

We will run analyses for reading times and 2afc task. 2afc task is operationalized here as the sum of the log probabilities across all words in the sentence. Reading time is operationalized as the sum of the log probabilities across our target region, consists of 6 words: the first word in the binomial to the 6th word after.

## Just Binomials

### 2afc

Technically, for just binomials, 2afc = reading times. Since 2afc is the probability of the sentence (sum of log probs for each item in the sentence), and reading times are the probability of a specific region in the sentence (sum of log probs for each item in a given region of the sentence).

In this case, the entire sentence is the region we care about. Thus for just binomials we run only one task for each language model.

Our main analyses will be:

$$
logit(P_{AandB}) \sim GenPref + OrderingPref + Overall Freq + OverallFreq \colon GenPref + OverallFreq \colon OrderingPref
$$

Where our dependent variable is the probability of the binomial being alphabetical form.

And the independent variables are the generative preference of a given binomial, the ordering preference, the overall frequency, and the interaction between overall frequency and generative preference as well as the interaction between overall frequency and the ordering preference.

We don't need a random intercept for item because we have one observation for each item, so this would be meaningless.

We also don't need a random intercept for "subject" because we don't have any subjects.

<!--# do we have no random effects here?? Surely I'm forgetting something -->

#### GPT2

Load data:

```{r}
gpt2_data_just_binoms = read_csv('../Data/gpt2_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus)
```

Quick and dirty historgram:

```{r}
ggplot(data = gpt2_data_just_binoms, aes(x=ProbAandB, y = ..density..)) +
  geom_histogram() +
  theme_bw()

ggplot(data = corpus, aes(x=RelFreq, y = ..density..)) +
  geom_histogram() +
  theme_bw()
```

Analysis:

```{r}
prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

gpt2_2afc_model_just_binoms = brm(data = gpt2_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/gpt2_2afc_model_just_binoms'
                      )

fixef(gpt2_2afc_model_just_binoms)

# mcmc_plot(
#   gpt2_2afc_model_just_binoms,
#   type = 'pairs',
#   off_diag_fun = 'hex',
#   diag_fun = 'dens',
#   fixed = T
# )
```

Checking posterior samples:

```{r}
post_samples_gpt2 = as.data.frame(fixef(gpt2_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_gpt2$GenPref < 0) / length(post_samples_gpt2$GenPref)
  
post_samples_genpref_freq = sum(post_samples_gpt2$`GenPref:OverallFreq` < 0) / length(post_samples_gpt2$`GenPref:OverallFreq`)

print(post_samples_genpref)
print(post_samples_genpref_freq)
```

#### GPT2-XL

Load data:

```{r}
gpt2xl_data_just_binoms = read_csv('../Data/gpt2xl_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus)


```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))

gpt2xl_2afc_model_just_binoms = brm(data = gpt2xl_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/gpt2xl_2afc_model_just_binoms'
                      )

fixef(gpt2xl_2afc_model_just_binoms)
```

Checking posterior samples for some of the effects:

```{r}
post_samples_gpt2xl = as.data.frame(fixef(gpt2xl_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_gpt2xl$GenPref < 0) / length(post_samples_gpt2xl$GenPref)
  
post_samples_genpref_freq = sum(post_samples_gpt2xl$`GenPref:OverallFreq` < 0) / length(post_samples_gpt2xl$`GenPref:OverallFreq`)

# post_samples_relfreq_freq = sum(post_samples_gpt2$`RelFreq:OverallFreq` > 0) / length(post_samples_gpt2$`RelFreq:OverallFreq`)

print(post_samples_genpref)
print(post_samples_genpref_freq)

```

#### Llama-7b

Load data:

```{r}
llama7b_data_just_binoms = read_csv('../Data/llama7b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))

llama7b_2afc_model_just_binoms = brm(data = llama7b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama7b_2afc_model_just_binoms'
                      )

fixef(llama7b_2afc_model_just_binoms)
```

Checking posterior:

```{r}
post_samples_llama7b = as.data.frame(fixef(llama7b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_llama7b$GenPref < 0) / length(post_samples_llama7b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama7b$`GenPref:OverallFreq` < 0) / length(post_samples_llama7b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama7b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama7b$`RelFreq:OverallFreq`)

print(post_samples_genpref)
print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

#### Llama-13b

Load data:

```{r}
llama13b_data_just_binoms = read_csv('../Data/llama13b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama13b_data_just_binoms = llama13b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama13b_data_just_binoms = llama13b_data_just_binoms %>%
  left_join(corpus)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama13b_2afc_model_just_binoms = brm(data = llama13b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama13b_2afc_model_just_binoms'
                      )

fixef(llama13b_2afc_model_just_binoms)
```

Checking posterior:

```{r}
post_samples_llama13b = as.data.frame(fixef(llama13b_2afc_model_just_binoms, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama13b$`GenPref:OverallFreq` < 0) / length(post_samples_llama13b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama13b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama13b$`RelFreq:OverallFreq`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

### Reweighting generative preferences

One possibility is that LLMs have learned to weight the generative constraints differently than humans. In this section, we re-weight the generative preferences per LLM preferences, and then run another set of models with the updated generative constraints.

#### Re-weighted constraints

##### GPT2

```{r}

```

##### GPT2-XL

```{r}

```

##### Llama-7b

```{r}

```

##### Llama-13b

```{r}

```

#### Analyses

##### GPT2

```{r}
options(contrasts = c("contr.sum","contr.sum"))

gpt2_2afc_model_just_binoms_reweighted = brm(data = gpt2_data_just_binoms_reweighted,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       file = '../Data/gpt2_2afc_model_just_binoms_reweighted'
                      )

fixef(gpt2_2afc_model_just_binoms_reweighted)
```

##### GPT2-XL

```{r}

options(contrasts = c("contr.sum","contr.sum"))

gpt2xl_2afc_model_just_binoms_reweighted = brm(data = gpt2xl_data_just_binoms_reweighted,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/gpt2xl_2afc_model_just_binoms_reweighted'
                      )

fixef(gpt2xl_2afc_model_just_binoms_reweighted)
```

##### Llama-7b

```{r}
options(contrasts = c("contr.sum","contr.sum"))

llama7b_2afc_model_just_binoms_reweighted = brm(data = llama7b_data_just_binoms_reweighted,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama7b_2afc_model_just_binoms_reweighted'
                      )

fixef(llama7b_2afc_model_just_binoms_reweighted)
```

##### Llama-13b

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama13b_2afc_model_just_binoms_reweighted = brm(data = llama13b_data_just_binoms_reweighted,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama13b_2afc_model_just_binoms_reweighted'
                      )

fixef(llama13b_2afc_model_just_binoms_reweighted)
```

### GAMMs

#### GPT2

#### GPT2-XL

#### Llama-7b

#### Llama-13b
